{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3665e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "import re\n",
    "import datetime as dt\n",
    "# now = dt.datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 진행 여부 함수\n",
    "def yes_or_no(question):\n",
    "    while \"the answer is invalid\":\n",
    "        reply = str(input(question+' (y/n): ')).lower().strip()\n",
    "        if reply[0] == 'y':\n",
    "            return True\n",
    "        if reply[0] == 'n':\n",
    "            return False\n",
    "        else:\n",
    "            print(\"실패: 'y' 혹은 'n' 를 입력해 주세요\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99abf27b",
   "metadata": {},
   "source": [
    "### 추가 1) 메타데이터 띄움처리 전 중복 제거..\n",
    "### 추가 2) 한글명 notnull vs null 분리하여 notnull만 관리(null: 파일 생성 및 기입 요청)\n",
    "### 추가 3.1) 한글 용어 점검 기능: 한글명+영문명+숫자조합 가능), 그외 모두 제거\n",
    "### 추가 3.2) 한글 단어 점검 기능: 한글명(숫자조합 가능), 영문명만(숫자조합 가능) 그외 모두 제거\n",
    "### 추가 4) 테이블기준 상세항목 정의하기.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준용어 구분자 변환 점검\n",
    "print(len('가 나 다'.split(\" \")))\n",
    "'가 나 다'.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1985d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "'가 나 다'.count(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af4817",
   "metadata": {},
   "source": [
    "# 한글명은 notNull이어야 함\n",
    "\n",
    "작업내용:\n",
    "1. 중복제거(unique): 작업 효율성 제고\n",
    "2. 개수 매칭 -> (모든 값 채우기)\n",
    "3. 순서 매칭: ID 부여, 한글/영문\n",
    "4. 재조립( 한글명 기준)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6df24",
   "metadata": {},
   "source": [
    "# 1. 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "# test_emoti_dup_korDup\n",
    "sheet_name = \"input_test\"\n",
    "input_path = os.path.join(os.getcwd(), \"input\\\\\")\n",
    "output_path = os.path.join(os.getcwd(), \"output\\\\\")\n",
    "# input_test = pd.read_excel(input_path+\"test_emoti_dup_korDup.xlsx\", sheet_name=sheet_name, header=0)\n",
    "input_test = pd.read_excel(input_path+\"test.xlsx\", sheet_name=sheet_name, header=0)\n",
    "# test_final.xlsx\n",
    "# null 제거\n",
    "for i in range(len(input_test.columns)):\n",
    "    input_test[input_test.columns[i]] = input_test[input_test.columns[i]].fillna(\"\")\n",
    "print(input_test.shape)\n",
    "input_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72962e36",
   "metadata": {},
   "source": [
    "# 2. 용어 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 DF 초기화\n",
    "df_index = pd.DataFrame(input_test['No'])\n",
    "df_index.columns = ['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07149992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 용어명 분리\n",
    "\n",
    "# 용어명 분리\n",
    "input_split_kor = pd.DataFrame(input_test['용어명 분리'].str.split('_').tolist()).fillna(\"\")\n",
    "\n",
    "# 영문명 없을 경우 대비하여 cnt 집계\n",
    "kor_firts_cnt = len(input_split_kor.columns)\n",
    "\n",
    "# 컬럼명 입력\n",
    "col_list_kor = []\n",
    "for i in range(len(input_split_kor.columns)):\n",
    "    col_list_kor.append(\"stwd_kor{}\".format(i))\n",
    "input_split_kor.columns = col_list_kor\n",
    "\n",
    "# 한글 개수 세기\n",
    "dupl_list_kor = []\n",
    "dupl_cnt_kor = []\n",
    "for i in range(kor_firts_cnt):\n",
    "    globals()[\"dupl_list_kor{}\".format(i)] = []\n",
    "    for j in range(len(input_split_kor[\"stwd_kor{}\".format(i)])):\n",
    "        dupl_list_kor = input_split_kor[\"stwd_kor{}\".format(i)].to_list().count(input_split_kor[\"stwd_kor{}\".format(i)][j])\n",
    "        globals()[\"dupl_list_kor{}\".format(i)].append(dupl_list_kor)\n",
    "for i in range(kor_firts_cnt):\n",
    "    globals()[\"dupl_list_kor{}\".format(i)] = pd.concat([pd.DataFrame(globals()[\"dupl_list_kor{}\".format(i)])], axis = 0)\n",
    "    globals()[\"dupl_list_kor{}\".format(i)].columns = [\"dupl_list_kor{}\".format(i)]\n",
    "    \n",
    "# 컬럼명,index, 단어위치 추가\n",
    "for i in range(len(input_split_kor.columns)):\n",
    "    input_split_kor[\"num_kor{}\".format(i)] = \"num_kor{}\".format(i)\n",
    "    globals()[\"stwd_kor{}\".format(i)] = pd.concat(\n",
    "            [\n",
    "            df_index.fillna(\"\"), \n",
    "            pd.DataFrame(input_split_kor[\"stwd_kor{}\".format(i)]).fillna(\"\"),\n",
    "            pd.DataFrame(input_split_kor[\"num_kor{}\".format(i)]).fillna(\"\"),\n",
    "            globals()[\"dupl_list_kor{}\".format(i)].fillna(\"\")\n",
    "            ], \n",
    "            axis=1)\n",
    "print(col_list_kor)\n",
    "print(kor_firts_cnt)\n",
    "# stwd_kor9\n",
    "# dupl_list_kor0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a82e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영문명 분리\n",
    "\n",
    "# 영문명이 하나라도 입력돼 있을 경우\n",
    "if len(input_test['영문약어명']) > 0:\n",
    "    print(\"영문명 컬럼 수 1개 이상:\"+str((input_test['영문약어명']==\"\").sum()))\n",
    "\n",
    "    # 영문명 분리\n",
    "    input_split_eng = pd.DataFrame(input_test['영문약어명'].str.split('_').tolist()).fillna(\"\")\n",
    "    \n",
    "    # 영문명 컬럼 수\n",
    "    eng_firts_cnt = len(input_split_eng.columns)\n",
    "    \n",
    "    # 컬럼명 입력\n",
    "    col_list_eng = []\n",
    "    for i in range(len(input_split_eng.columns)):\n",
    "        col_list_eng.append(\"stwd_eng{}\".format(i))\n",
    "    input_split_eng.columns = col_list_eng\n",
    "    \n",
    "    # 영문 개수 세기\n",
    "    dupl_list_eng = []\n",
    "    dupl_cnt_eng = []\n",
    "    for i in range(eng_firts_cnt):\n",
    "        globals()[\"dupl_list_eng{}\".format(i)] = []\n",
    "        for j in range(len(input_split_eng[\"stwd_eng{}\".format(i)])):\n",
    "            dupl_list_eng = input_split_eng[\"stwd_eng{}\".format(i)].to_list().count(input_split_eng[\"stwd_eng{}\".format(i)][j])\n",
    "            globals()[\"dupl_list_eng{}\".format(i)].append(dupl_list_eng)\n",
    "    for i in range(eng_firts_cnt):\n",
    "        globals()[\"dupl_list_eng{}\".format(i)] = pd.concat([pd.DataFrame(globals()[\"dupl_list_eng{}\".format(i)])], axis = 0)\n",
    "        globals()[\"dupl_list_eng{}\".format(i)].columns = [\"dupl_list_eng{}\".format(i)]\n",
    "        \n",
    "    # 컬럼명,index, 단어위치 추가\n",
    "    for i in range(eng_firts_cnt):\n",
    "        input_split_eng[\"num_eng{}\".format(i)] = \"num_eng{}\".format(i)\n",
    "        globals()[\"stwd_eng{}\".format(i)] = pd.concat(\n",
    "                [\n",
    "                df_index.fillna(\"\"), \n",
    "                pd.DataFrame(input_split_eng[\"stwd_eng{}\".format(i)].fillna(\"\")),\n",
    "                pd.DataFrame(input_split_eng[\"num_eng{}\".format(i)].fillna(\"\")),\n",
    "                globals()[\"dupl_list_eng{}\".format(i)].fillna(\"\")\n",
    "                ], \n",
    "                axis=1)\n",
    "        \n",
    "# 영문명이 없을 경우\n",
    "elif len(input_test['영문약어명']) == 0:\n",
    "    print(\"영문명 컬럼 수 0개:\"+str((input_test['영문약어명']==\"\").sum()))\n",
    "    \n",
    "    col_list_eng = []\n",
    "    for i in range(kor_firts_cnt):\n",
    "        globals()[\"stwd_eng{}\".format(i)] = pd.DataFrame(columns = [\"stwd_eng{}\".format(i)])\n",
    "        globals()[\"num_eng{}\".format(i)] = pd.DataFrame(columns = [\"num_eng{}\".format(i)])\n",
    "        globals()[\"dupl_list_eng{}\".format(i)] = pd.DataFrame(columns = [\"dupl_list_eng{}\".format(i)])\n",
    "        globals()[\"stwd_eng{}\".format(i)] = pd.concat(\n",
    "            [\n",
    "                df_index.fillna(\"\"), \n",
    "                globals()[\"stwd_eng{}\".format(i)].fillna(\"\"),\n",
    "                globals()[\"num_eng{}\".format(i)].fillna(\"\"),\n",
    "                globals()[\"dupl_list_eng{}\".format(i)].fillna(\"\"),\n",
    "            ]\n",
    "            , axis = 1\n",
    "        )\n",
    "        globals()[\"stwd_eng{}\".format(i)][\"num_eng{}\".format(i)] = \"num_eng{}\".format(i)\n",
    "        globals()[\"stwd_eng{}\".format(i)][\"dupl_list_eng{}\".format(i)] = len(globals()[\"stwd_eng{}\".format(i)])\n",
    "        col_list_eng.append(\"stwd_eng{}\".format(i))\n",
    "        \n",
    "else:\n",
    "    print(\"한글컬럼, 영문커럼 예외 사항\")\n",
    "\n",
    "# 컬럼수 일치 점검\n",
    "col_cnt_kor = len(col_list_kor)\n",
    "col_cnt_eng = len(col_list_eng)\n",
    "if len(col_list_kor) == len(col_list_eng):\n",
    "    print(\"한글컬럼수와 영문컬럼수 일치\")\n",
    "    print(\"kor:\" + str(col_cnt_kor) + \" vs eng:\" + str(col_cnt_eng))\n",
    "else:\n",
    "    print(\"한글컬럼수와 영문컬럼수 불일치\")\n",
    "    print(\"kor:\" + str(col_cnt_kor) + \" vs eng:\" + str(col_cnt_eng))                                                       \n",
    "print(col_list_eng)\n",
    "stwd_eng0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a4c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글/영문 컬럼 수 일치시키기\n",
    "\n",
    "# 한글컬럼과 영문컬럼 수 일치할 경우\n",
    "if col_cnt_kor == col_cnt_eng:\n",
    "    col_cnt = col_cnt_kor\n",
    "    col_cnt_diff_list = None\n",
    "    col_cnt_diff = None\n",
    "    print('한글컬럼과 영문컬럼 수 일치')\n",
    "    print(\"kor:\" + str(col_cnt_kor) + \" vs eng:\" + str(col_cnt_eng))\n",
    "    print(\"컬럼수 일치작업 후:\" + str(col_cnt))  \n",
    "    \n",
    "# 한글컬럼이 더 많을 경우\n",
    "elif col_cnt_kor > col_cnt_eng:\n",
    "    col_cnt = col_cnt_kor\n",
    "    col_cnt_diff_list = list(set(range(col_cnt_kor)) - set(range(col_cnt_eng)))\n",
    "    col_cnt_diff = len(col_cnt_diff_list)\n",
    "    for i in col_cnt_diff_list:\n",
    "        input_split_eng['stwd_eng{}'.format(i)] = None\n",
    "        input_split_eng['num_eng{}'.format(i)] = None\n",
    "        input_split_eng['dupl_list_eng{}'.format(i)] = None\n",
    "        globals()['stwd_eng{}'.format(i)] = pd.concat(\n",
    "            [\n",
    "                df_index,\n",
    "                pd.DataFrame(input_split_eng['stwd_eng{}'.format(i)].fillna(\"\")),\n",
    "                pd.DataFrame(input_split_eng[\"num_eng{}\".format(i)].fillna(\"\")),\n",
    "                pd.DataFrame(input_split_eng[\"dupl_list_eng{}\".format(i)].fillna(\"\"))\n",
    "            ],\n",
    "            axis = 1\n",
    "        )\n",
    "    print('한글컬럼이 더 많은 싱태')\n",
    "    print(\"kor:\" + str(col_cnt_kor) + \" vs eng:\" + str(col_cnt_eng))\n",
    "    print(\"컬럼수 일치작업 후:\" + str(col_cnt))  \n",
    "\n",
    "# 영문컬럼이 더 많을 경우\n",
    "elif col_cnt_kor < col_cnt_eng:\n",
    "    col_cnt = col_cnt_eng\n",
    "    col_cnt_diff_list = list(set(range(col_cnt_eng)) - set(range(col_cnt_kor)))\n",
    "    col_cnt_diff = len(col_cnt_diff_list)\n",
    "    for i in col_cnt_diff_list:\n",
    "        input_split_kor['stwd_kor{}'.format(i)] = None\n",
    "        input_split_kor['num_kor{}'.format(i)] = None\n",
    "        input_split_eng['dupl_list_kor{}'.format(i)] = None\n",
    "        globals()['stwd_kor{}'.format(i)] = pd.concat(\n",
    "            [\n",
    "                df_index,\n",
    "                pd.DataFrame(input_split_kor['stwd_kor{}'.format(i)].fillna(\"\")),\n",
    "                pd.DataFrame(input_split_kor[\"num_kor{}\".format(i)].fillna(\"\")).\n",
    "                pd.DataFrame(input_split_eng[\"dupl_list_kor{}\".format(i)].fillna(\"\"))\n",
    "            ],\n",
    "            axis = 1\n",
    "        )\n",
    "    print('영문컬럼이 더 많은 싱태')       \n",
    "    print(\"kor:\" + str(col_cnt_kor) + \" vs eng:\" + str(col_cnt_eng))\n",
    "    print(\"컬럼수 일치작업 후:\" + str(col_cnt))  \n",
    "stwd_eng3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28047c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n x m 정사각형 DafaFrame 점검\n",
    "for i in range(col_cnt_kor):\n",
    "    for j in range(len(globals()[\"stwd_kor{}\".format(i)])):\n",
    "        cnt = (j + 1)\n",
    "    avg = np.mean(cnt)\n",
    "avg_avg_kor = round(np.mean(avg), 2)\n",
    "for i in range(col_cnt_eng):\n",
    "    for j in range(len(globals()[\"stwd_kor{}\".format(i)])):\n",
    "        cnt = (j + 1)\n",
    "    avg = np.mean(cnt)\n",
    "avg_avg_eng = round(np.mean(avg), 2)\n",
    "stwd_total_cnt = int(avg_avg_eng)\n",
    "if avg_avg_kor == avg_avg_eng:\n",
    "    print(\"한글 영문 row수 일치: 평균=\" + str((avg_avg_kor + avg_avg_eng)/2))\n",
    "    print(\"한글평균:\" + str(avg_avg_kor) + \", 영문평균:\" + str(avg_avg_eng) + \", 최종count:\" + str(stwd_total_cnt))\n",
    "else:\n",
    "    yes_or_no(\"한글명과 영문명의 row count가 일치하지 않습니다. 계속 진행하시겠습니까?\")\n",
    "    print(\"한글 영문 row수 불일치: 평균\" + str((avg_avg_kor + avg_avg_eng)/2))\n",
    "    print(\"한글평균:\" + str(avg_avg_kor) + \", 영문평균:\" + str(avg_avg_eng) + \", 최종count:\" + str(stwd_total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad007a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복검사를 위한 left join\n",
    "for i in range(col_cnt):\n",
    "    globals()['stwd_total{}'.format(i)] = pd.merge(\n",
    "        globals()['stwd_kor{}'.format(i)],\n",
    "        globals()['stwd_eng{}'.format(i)],\n",
    "        on = 'index',\n",
    "        how = 'left'\n",
    "    )\n",
    "print(col_cnt)\n",
    "# stwd_total9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일렬 세우기\n",
    "\n",
    "# unique_stwd 초기화 \n",
    "stwd_total = pd.DataFrame()\n",
    "\n",
    "## 컬럼명 바꾸고  concat\n",
    "for i in range(col_cnt):\n",
    "    globals()[\"stwd_total{}\".format(i)].columns = [\n",
    "        'index', 'stwd_kor', 'num_kor', 'dupl_list_kor', 'stwd_eng','num_eng', 'dupl_list_eng'\n",
    "    ]\n",
    "    stwd_total = pd.concat([stwd_total, globals()[\"stwd_total{}\".format(i)]], axis = 0, ignore_index = True)\n",
    "print(stwd_total.shape)\n",
    "stwd_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2efbd8",
   "metadata": {},
   "source": [
    "# 3. 이상값 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01751d87",
   "metadata": {},
   "source": [
    "### 3.1. 한글명에 한글과 영문대문자, 숫자 이외 표시 및 삭제 로직"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d0f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoti_chk(var):\n",
    "    if var == 'kor':\n",
    "        # 한글명에 영문 소문자 탐색\n",
    "        stwd_total = globals()['stwd_total']\n",
    "        df_lower_kor = pd.DataFrame(columns = stwd_total.columns)        \n",
    "        stwd_total['kor_lower'] = ''\n",
    "        stwd_total['kor_ec'] = ''\n",
    "        kor_chk_list = []\n",
    "        for i in range(len(stwd_total)):\n",
    "\n",
    "        #     특수기호 제거\n",
    "        #     stwd_total.loc[i, 'stwd_kor'] =  stwd_total.loc[i, 'stwd_kor'].translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "            # 영문 소문자 체크 및 기록\n",
    "            if stwd_total.loc[i, 'stwd_kor'].islower():\n",
    "                tmp = pd.DataFrame(stwd_total.iloc[i,:]).transpose()\n",
    "                df_lower_kor = pd.concat([df_lower_kor, tmp], axis=0)\n",
    "                print(\"----------------------영문 소문자 체크 및 기록--------------------|\")\n",
    "                print('index: ' + str(i))\n",
    "                print(stwd_total.loc[i, 'stwd_kor'] + \" -> \" + str(stwd_total.loc[i, 'stwd_kor'].upper()))\n",
    "                kor_chk_list.append(i)\n",
    "\n",
    "                # 영문 변경 이력 저장\n",
    "                stwd_total.loc[i, 'kor_lower'] = stwd_total.loc[i, 'stwd_kor']      \n",
    "\n",
    "                # 영문 대문자 변경\n",
    "                stwd_total.loc[i, 'stwd_kor'] = stwd_total.loc[i, 'stwd_kor'].upper()\n",
    "\n",
    "            # 영문 대문자, 숫자, 한글만 체크\n",
    "            cor_kor = re.findall('[A-Z0-9가-힣+]', stwd_total.loc[i, 'stwd_kor'])\n",
    "            chk_kor = len(cor_kor) == len(list(stwd_total.loc[i, 'stwd_kor']))\n",
    "\n",
    "            if bool(chk_kor) == False:\n",
    "                print(\"-----------------------------특수기호제거----------------------------|\")\n",
    "                print('index: ' + str(i))\n",
    "                print(stwd_total.loc[i, 'stwd_kor'] + \" -> \" + str(''.join(cor_kor)))\n",
    "                kor_chk_list.append(i)\n",
    "\n",
    "            # 영문대문자, 숫자, 한글 외 변경 이력 저장\n",
    "            stwd_total.loc[i, 'kor_ec'] = re.sub('[A-Z0-9가-힣+]', '', stwd_total.loc[i, 'stwd_kor'])        \n",
    "\n",
    "            # 영문대문자, 숫자, 한글 외 자동 삭제\n",
    "            stwd_total.loc[i, 'stwd_kor'] = ''.join(cor_kor)\n",
    "\n",
    "        # 변경 이력 저장\n",
    "        stwd_total['kor_cor_hist'] = \"\"\n",
    "        stwd_total['kor_cor_hist'] = stwd_total['kor_lower'] + stwd_total['kor_ec']\n",
    "\n",
    "        # 적용 후 결과값\n",
    "        print(\"====================================한글명 검토====================================|\")\n",
    "        print('소문자 처리: ' + str(len(df_lower_kor)) + '개')\n",
    "        stwd_total_kor_chk_1 = stwd_total.iloc[kor_chk_list]\n",
    "        print(\"나머지 제거: \"+ str(len(kor_chk_list)))\n",
    "        print('[자동 처리 완료하였습니다]')\n",
    "\n",
    "    elif var == 'eng':\n",
    "        # 영문명에 영문 소문자 탐색\n",
    "        stwd_total = globals()['stwd_total']\n",
    "        df_lower_eng = pd.DataFrame(columns = stwd_total.columns)        \n",
    "        stwd_total['eng_lower'] = ''\n",
    "        stwd_total['eng_ec'] = ''\n",
    "        eng_chk_list = []\n",
    "        for i in range(len(stwd_total)):\n",
    "\n",
    "            # 영문 소문자 체크 및 기록\n",
    "            if stwd_total.loc[i, 'stwd_eng'].islower():\n",
    "                tmp = pd.DataFrame(stwd_total.iloc[i,:]).transpose()\n",
    "                df_lower_eng = pd.concat([df_lower_eng, tmp], axis=0)\n",
    "                print(\"----------------------영문 소문자 체크 및 기록--------------------|\")\n",
    "                print('index: ' + str(i))\n",
    "                print(stwd_total.loc[i, 'stwd_eng'] + \" -> \" + str(stwd_total.loc[i, 'stwd_eng'].upper()))\n",
    "                eng_chk_list.append(i)\n",
    "\n",
    "                # 영문 변경 이력 저장\n",
    "                stwd_total.loc[i, 'eng_lower'] = stwd_total.loc[i, 'stwd_eng']      \n",
    "\n",
    "                # 영문 대문자 변경\n",
    "                stwd_total.loc[i, 'stwd_eng'] = stwd_total.loc[i, 'stwd_eng'].upper()\n",
    "\n",
    "            # 영문 대문자, 숫자, 한글만 체크\n",
    "            cor_eng = re.findall('[A-Z0-9+]', stwd_total.loc[i, 'stwd_eng'])\n",
    "            chk_eng = len(cor_eng) == len(list(stwd_total.loc[i, 'stwd_eng']))\n",
    "\n",
    "            if bool(chk_eng) == False:\n",
    "                print(\"-----------------------------특수기호제거----------------------------|\")\n",
    "                print('index: ' + str(i))\n",
    "                print(stwd_total.loc[i, 'stwd_eng'] + \" -> \" + str(''.join(cor_eng)))\n",
    "                eng_chk_list.append(i)\n",
    "\n",
    "            # 영문대문자, 숫자 외 변경 이력 저장\n",
    "            stwd_total.loc[i, 'eng_ec'] = re.sub('[A-Z0-9+]', '', stwd_total.loc[i, 'stwd_eng'])        \n",
    "\n",
    "            # 영문대문자, 숫자 외 자동 삭제\n",
    "            stwd_total.loc[i, 'stwd_eng'] = ''.join(cor_eng)\n",
    "\n",
    "        # 변경 이력 저장\n",
    "        stwd_total['eng_cor_hist'] = ''\n",
    "        stwd_total['eng_cor_hist'] = stwd_total['eng_lower'] + stwd_total['eng_ec']\n",
    "\n",
    "        # 적용 후 결과값\n",
    "        print(\"====================================영문명 검토====================================|\")\n",
    "        print('소문자 처리: ' + str(len(df_lower_eng)) + '개')\n",
    "        stwd_total_eng_chk_1 = stwd_total.iloc[eng_chk_list]\n",
    "        print(\"나머지 제거: \"+ str(len(eng_chk_list)))\n",
    "        print('[자동 처리 완료하였습니다]')\n",
    "        \n",
    "    else:\n",
    "        print(\"잘못된 입력입니다( 'kor' / 'eng' )\")\n",
    "# 데이터 검토\n",
    "ans = yes_or_no(\"데이터 검토를 실행 하시겠습니까?\")\n",
    "if ans == True:\n",
    "    emoti_chk('kor')\n",
    "    emoti_chk('eng')\n",
    "elif ans == False:\n",
    "    print(\"계속 진행하겠습니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92641bf1",
   "metadata": {},
   "source": [
    "### 3.2. 특수문자 제거 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45dbbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경 체크 로직\n",
    "\n",
    "s1 = '고구마acAB1!$%@! 32'\n",
    "s2 = '깎ㅉ니'\n",
    "s3 = \"RR깍찌니12\"\n",
    "s4 = \"123깍찌니aS\"\n",
    "print(\"------------------------------------------------------\")\n",
    "print(re.findall('[A-Z0-9가-힣+]', s1))\n",
    "print(str(len(re.findall('[A-Z0-9가-힣+]', s1))) + \" vs \" + str(len(list(s1))))\n",
    "print(len(re.findall('[A-Z0-9가-힣+]', s1)) == len(list(s1)))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(re.findall('[A-Z0-9가-힣+]', s2))\n",
    "print(str(len(re.findall('[A-Z0-9가-힣+]', s2))) + \" vs \" + str(len(list(s2))))\n",
    "print(len(re.findall('[A-Z0-9가-힣+]', s2)) == len(list(s2)))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(re.findall('[A-Z0-9가-힣+]', s3))\n",
    "print(str(len(re.findall('[A-Z0-9가-힣+]', s3))) + \" vs \" + str(len(list(s3))))\n",
    "print(len(re.findall('[A-Z0-9가-힣+]', s3)) == len(list(s3)))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(re.findall('[A-Z0-9가-힣+]', s4))\n",
    "print(str(len(re.findall('[A-Z0-9가-힣+]', s4))) + \" vs \" + str(len(list(s4))))\n",
    "print(len(re.findall('[A-Z0-9가-힣+]', s4)) == len(list(s4)))\n",
    "print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3450a75f",
   "metadata": {},
   "source": [
    "# 4. 공통 표준 우선 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yes_or_no(\"공통 표준으로 통일 하시겠습니까?\"):\n",
    "\n",
    "    # 표준 파일 불러오기\n",
    "    sheet_name = \"공통표준단어\"\n",
    "    input_path = os.path.join(os.getcwd(), \"input\\\\\")\n",
    "    public_stwd = pd.read_excel(input_path + \"공공데이터 공통표준용어(2021.12월).xlsx\", sheet_name=sheet_name, header=0)\n",
    "    public_stwd = public_stwd[['NO', '공통표준단어명', '공통표준단어영문약어명']]\n",
    "\n",
    "    # 표준 영문명 자동 기입(널 제외)\n",
    "\n",
    "    # 표준 단어명 기준 left join (영문명이 null이면 비표준, notnull이면 표준)\n",
    "    std_chk = stwd_total.merge(public_stwd, left_on = 'stwd_kor', right_on = '공통표준단어명', how = 'left')\n",
    "    for i in range(std_chk.shape[0]):\n",
    "        \n",
    "        # joined DF의 영문명이 있을 경우 표준으로 대신 기입 \n",
    "        notna_chk = std_chk['stwd_eng'].notna()[i]\n",
    "        if notna_chk:\n",
    "            std_chk.loc[i, 'stwd_eng'] = std_chk.loc[i, '공통표준단어영문약어명']\n",
    "\n",
    "    std_chk_list = ['index', 'stwd_kor', 'num_kor', 'stwd_eng', 'num_eng']\n",
    "    std_chk = std_chk[std_chk_list]\n",
    "    \n",
    "    print('한글명을 기준으로 공통(행안부) 표준을 우선 적용합니다.')\n",
    "else:\n",
    "    print('공통(행안부) 표준을 우선 적용하지 않고 표준화를 진행합니다.')\n",
    "    \n",
    "print(std_chk.shape)\n",
    "std_chk.tail()\n",
    "std_chk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd65a0c",
   "metadata": {},
   "source": [
    "# 5. 한/영  중복제거 및 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글명 중복 검사: 수기 수정 후 최대 unique 값 카운트\n",
    "def find_unique_eng(df):\n",
    "    \n",
    "    kor_input_cnt = sum(df_step_1['stwd_kor'].notna())\n",
    "    kor_unique_cnt = len(set(df_step_1['stwd_kor']))\n",
    "    eng_input_cnt = sum(df_step_1['stwd_eng'].notna())\n",
    "    eng_unque_cnt = len(set(df_step_1['stwd_eng']))\n",
    "    \n",
    "    print(\"==중복값 비교==\")\n",
    "    # (한)미입력값 개수\n",
    "    print('(한)     not null   개수: ' + str(kor_input_cnt))\n",
    "    # (한)unique 값 개수\n",
    "    print(\"(한)''포함 unique값 개수: \" + str(kor_unique_cnt)) \n",
    "    # (영)미입력값 개수\n",
    "    print('(영)     not null   개수: ' + str(eng_input_cnt))\n",
    "    # (영)unique 값 개수\n",
    "    print(\"(영)''포함 unique값 개수: \" + str(eng_unque_cnt)) \n",
    "    \n",
    "    if (kor_input_cnt == eng_input_cnt) and (kor_unique_cnt == eng_unque_cnt):\n",
    "        print('\"한글명과 영문명의 unique 개수가 같습니다.\"')\n",
    "    else:\n",
    "        print('\"한글명과 영문명의 unique 개수가 다릅니다.\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chk_unique():\n",
    "    global df_step_1   \n",
    "    df_step_1 = std_chk\n",
    "    # 중복제거 후 다시 합쳐서 검사(1안)\n",
    "\n",
    "    # 한글 중복제거\n",
    "    col_stwd_kor = ['stwd_kor', 'num_kor']\n",
    "    unique_kor = df_step_1['stwd_kor'].drop_duplicates()\n",
    "    stwd_kor_unique = df_step_1.loc[unique_kor.index][col_stwd_kor]\n",
    "    print(\"한글명중복제거:\"+ str(stwd_kor_unique.shape))\n",
    "    # stwd_kor_unique\n",
    "\n",
    "    # 영문 중복제거\n",
    "    col_stwd_eng = ['stwd_eng', 'num_eng']\n",
    "    unique_eng = df_step_1['stwd_eng'].drop_duplicates()\n",
    "    stwd_eng_unique = df_step_1.loc[unique_eng.index][col_stwd_eng]\n",
    "    print(\"영문명중복제거:\"+ str(stwd_eng_unique.shape))\n",
    "    # stwd_eng_unique.tail(100)\n",
    "\n",
    "    # 한글+영문 일렬 세우기\n",
    "    df_step_1 = pd.DataFrame(stwd_total['index'])\n",
    "    df_step_1 = df_step_1.merge(\n",
    "        stwd_kor_unique,\n",
    "        left_index = True,\n",
    "        right_index = True,\n",
    "        how = 'left'\n",
    "    ).merge(\n",
    "        stwd_eng_unique,\n",
    "        left_index = True,\n",
    "        right_index = True,\n",
    "        how = 'left'\n",
    "    )\n",
    "    print(df_step_1.shape)\n",
    "    df_step_1\n",
    "\n",
    "    df_step_1.to_excel(input_path + \"df_step_1\" + str(dt.datetime.now().strftime('%y%m%d_%H%M%S')) + \".xlsx\")\n",
    "    print(df_step_1.shape)\n",
    "    df_step_1\n",
    "    \n",
    "chk_unique()\n",
    "find_unique_eng(df_step_1)\n",
    "df_step_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a25c5",
   "metadata": {},
   "source": [
    "# * 한글/영문 단어수 매칭"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab910728",
   "metadata": {},
   "source": [
    "## 6. 자동수정, 파일 업로드 점검"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f00aa35",
   "metadata": {},
   "source": [
    "### 6.1.수기 수정값 표시(! y/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c667092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 값이 한개라도 있을 경우만 카운트 ###\n",
    "\n",
    "df_step_1_cnt = len(df_step_1)\n",
    "notna_list = []\n",
    "for i in range(df_step_1_cnt):    \n",
    "    # row 기준 널 체크(값이 한개라도 있을 경우 포함)\n",
    "    if df_step_1.iloc[i].notna().sum() > 1:\n",
    "        notna_list.append(i)\n",
    "\n",
    "df_step_1 = df_step_1.loc[notna_list]\n",
    "print(df_step_1.shape)\n",
    "\n",
    "# 원래 표준과 병합(수기 수정을 위해)\n",
    "df_step_1 = df_step_1.merge(\n",
    "    input_test,\n",
    "    left_on = 'index',\n",
    "    right_on = 'No',\n",
    "    how = 'left'\n",
    ")\n",
    "\n",
    "# 영문 개수 세기\n",
    "dup_list_eng = []\n",
    "dup_cnt_eng = []\n",
    "for i in range(df_step_1.shape[0]):\n",
    "    dup_list_eng = df_step_1['stwd_eng'].to_list().count(df_step_1.loc[i, 'stwd_eng'])\n",
    "    dup_cnt_eng.append(dup_list_eng)\n",
    "df_step_1 = pd.concat([df_step_1, pd.DataFrame(dup_cnt_eng, columns = {\"eng_cnt\"})], axis = 1)\n",
    "\n",
    "# 컬럼 추리기\n",
    "df_step_1_list = ['index', 'stwd_eng', 'stwd_kor', '영문약어명', '용어명 분리', 'eng_cnt']\n",
    "df_step_1 = df_step_1[df_step_1_list]\n",
    "\n",
    "# 비교군 저장\n",
    "df_step_1_chk = df_step_1.copy()\n",
    "df_step_1.head()\n",
    "\n",
    "# 2차\n",
    "# 널 제외 한글단어를 표준화된 풀데이터(df_step_1)를 다시검색하여 영문명 자동 기입 : 없는 것은 수동기입 필요 \n",
    "\n",
    "# 영문 null 값 '' 채우기\n",
    "df_step_1['stwd_eng'] = df_step_1['stwd_eng'].fillna(\"\")\n",
    "\n",
    "df_step_1['eng_cor_yn'] = \"\"\n",
    "for i in range(df_step_1.shape[0]):\n",
    "    blnk_chk = df_step_1.loc[i, 'stwd_eng'] == ''\n",
    "    if blnk_chk :\n",
    "        df_step_1.loc[i, 'stwd_eng'] = '!' + '_'.join(set(stwd_total.loc[(stwd_total['stwd_kor'] == df_step_1.loc[i, 'stwd_kor']), 'stwd_eng'].to_list()))\n",
    "        df_step_1.loc[i, 'eng_cor_yn'] = 'n'\n",
    "\n",
    "df_step_1_chk = df_step_1.copy()\n",
    "        \n",
    "# 순서\n",
    "df_step_1_xlsx = df_step_1.sort_values(['stwd_eng'])\n",
    "df_step_1_xlsx = df_step_1_xlsx[df_step_1_xlsx['eng_cor_yn'] == 'n']\n",
    "df_step_1_xlsx.to_excel(output_path+\"chk_eng\" + \".xlsx\")\n",
    "\n",
    "print(df_step_1_xlsx.shape)\n",
    "df_step_1_xlsx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2fce4",
   "metadata": {},
   "source": [
    "### 6.2. 수정 후 재업로드(한글): 개발 미정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a2dfe2",
   "metadata": {},
   "source": [
    "### 6.3. 수정 후 재업로드(영문)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b81ea",
   "metadata": {},
   "source": [
    "#### 6.3.1. 자동수정 후 재업로드(영문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831294a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 최초 1회 수정 후 재업로드\n",
    "\n",
    "# 수기 수정된 데이터\n",
    "######## 가짜, 추후(chk_eng)로 수정 ########\n",
    "re_load = pd.read_excel(output_path + 'chk_eng_test.xlsx', index_col='Unnamed: 0')\n",
    "\n",
    "# 주소값 덮어쓰지 않게 따로 복사하기\n",
    "df_step_1_cor = df_step_1.copy()\n",
    "\n",
    "# 모두null일 경우, 그냥 진행, 그렇지 않을 경우 수정된 값 적용 후 진행ㅇ\n",
    "# Index 병합, 수기수정 대입, 그 외 null 지정\n",
    "if re_load['stwd_eng'].isna().all():\n",
    "    pirnt(\"검수 통과\")\n",
    "else: \n",
    "    df_step_1_cor['stwd_eng'] =  re_load['stwd_eng']\n",
    "    print(\"수기 수정 다시\")\n",
    "    \n",
    "# 나머지 null 값은 본래 데이터(df_step_1) 값으로 채워넣기\n",
    "for i in range(df_step_1_cor.shape[0]):\n",
    "    if pd.isna(df_step_1_cor.loc[i, 'stwd_eng']):\n",
    "        df_step_1_cor.loc[i, 'stwd_eng'] = df_step_1.loc[i, 'stwd_eng']\n",
    "        df_step_1_cor.loc[i, 'eng_cor_yn'] = 'y'\n",
    "\n",
    "    if df_step_1_cor.loc[i, 'eng_cor_yn'] == 'n':\n",
    "        if df_step_1_cor.loc[i, 'stwd_eng'] != df_step_1_chk.loc[i, 'stwd_eng']:\n",
    "            df_step_1_cor.loc[i, 'eng_cor_yn'] = 'y'\n",
    "        elif df_step_1_cor.loc[i, 'stwd_eng'] == df_step_1_chk.loc[i, 'stwd_eng']:\n",
    "            df_step_1_cor.loc[i, 'eng_cor_yn'] = 'n'\n",
    "\n",
    "# 특수문자, 빈칸, null 점검\n",
    "tmp_list = []\n",
    "for i in range(df_step_1_cor.shape[0]):\n",
    "    if len(re.findall('[^A-Z0-9+]', df_step_1_cor.loc[i, 'stwd_eng'])):\n",
    "        tmp_list.append(i)\n",
    "    elif df_step_1_cor.loc[i, 'stwd_eng'] == '':\n",
    "        tmp_list.append(i)\n",
    "    elif pd.isna(df_step_1_cor.loc[i, 'stwd_eng']):\n",
    "        tmp_list.append(i)\n",
    "\n",
    "# 특수문자 'n'으로\n",
    "df_step_1_cor.loc[tmp_list, 'eng_cor_yn'] = 'n'\n",
    "\n",
    "# 전체 파일 저장\n",
    "df_step_1_cor.to_excel(output_path + \"df_step_1_cor.xlsx\")\n",
    "\n",
    "# 영문 점검 파일 저장    \n",
    "chk_eng = df_step_1_cor.loc[df_step_1_cor['eng_cor_yn'] == 'n']\n",
    "chk_eng.to_excel(output_path + \"chk_eng.xlsx\")\n",
    "print(df_step_1_cor.shape)\n",
    "df_step_1_cor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b3d43",
   "metadata": {},
   "source": [
    "#### 6.3.2. 수기수정 후 재업로드(영문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주소값 덮어쓰지 않게 따로 복사하기\n",
    "df_step_1_cor_tmp = df_step_1_cor.copy()\n",
    "# 2회 이상부터\n",
    "\n",
    "def repeat_eng():\n",
    "    global df_step_1_cor_tmp\n",
    "    global chk_eng\n",
    "    global tmp_list_eng\n",
    "#     global re_load\n",
    "\n",
    "    # 수기 수정 후 다시 업로드: na_filter=False\n",
    "    re_load = pd.read_excel(output_path + 'chk_eng.xlsx', index_col='Unnamed: 0', na_filter=False)\n",
    "    \n",
    "    # Index 병합, 수기수정 대입, 그 외 ''null'' 지정\n",
    "    for i in re_load['stwd_eng'].index:\n",
    "        df_step_1_cor_tmp.loc[i, 'stwd_eng'] =  re_load.loc[i, 'stwd_eng']\n",
    "    \n",
    "    # 나머지 null 값은 본래 데이터(df_step_1) 값으로 채워넣기\n",
    "    for i in range(df_step_1_cor_tmp.shape[0]):\n",
    "        if df_step_1_cor_tmp.loc[i, 'eng_cor_yn'] == 'n':\n",
    "            if df_step_1_cor_tmp.loc[i, 'stwd_eng'] != df_step_1_chk.loc[i, 'stwd_eng']:\n",
    "                df_step_1_cor_tmp.loc[i, 'eng_cor_yn'] = 'y'\n",
    "            elif df_step_1_cor_tmp.loc[i, 'stwd_eng'] == df_step_1_chk.loc[i, 'stwd_eng']:\n",
    "                df_step_1_cor_tmp.loc[i, 'eng_cor_yn'] = 'n'\n",
    "                \n",
    "        if pd.isna(df_step_1_cor_tmp.loc[i, 'stwd_eng']):\n",
    "            df_step_1_cor_tmp.loc[i, 'stwd_eng'] = df_step_1_cor.loc[i, 'stwd_eng']\n",
    "            df_step_1_cor_tmp.loc[i, 'eng_cor_yn'] = 'y'\n",
    "\n",
    "    # 특수문자, 빈칸, 소문자, 한글, null 점검\n",
    "    tmp_list_eng = []\n",
    "    for i in range(df_step_1_cor_tmp.shape[0]):\n",
    "        if len(re.findall('[^A-Z0-9+]', df_step_1_cor_tmp.loc[i, 'stwd_eng'])):\n",
    "            tmp_list_eng.append(i)\n",
    "        elif df_step_1_cor_tmp.loc[i, 'stwd_eng'] == '':\n",
    "            tmp_list_eng.append(i)\n",
    "        elif pd.isna(df_step_1_cor_tmp.loc[i, 'stwd_eng']):\n",
    "            tmp_list_eng.append(i)\n",
    "\n",
    "\n",
    "    # 특수문자 'n'으로\n",
    "    df_step_1_cor_tmp.loc[tmp_list_eng, 'eng_cor_yn'] = 'n'\n",
    "\n",
    "    # 파일 실행\n",
    "    os.system(output_path + \"chk_eng.xlsx\")\n",
    "\n",
    "    # 파일 저장\n",
    "    chk_eng = df_step_1_cor_tmp.loc[df_step_1_cor_tmp['eng_cor_yn'] == 'n']\n",
    "    df_step_1_cor_tmp.to_excel(output_path + \"df_step_1_cor.xlsx\")\n",
    "    chk_eng.to_excel(output_path + \"chk_eng.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6783f",
   "metadata": {},
   "source": [
    "#### 6.3.3. 재업로드 반복 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b54a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글명, 영문명이 모두 ''값일 경우, 수정 완료\n",
    "if (chk_eng[['stwd_kor', 'stwd_eng']] == '').all().all():\n",
    "    repeat_eng()\n",
    "    print('\"영문 수정 완료\"' + \" (빈칸 수:\" + str(sum(df_step_1_cor_tmp['stwd_eng'] == '')) + \")\")\n",
    "    os.system(output_path + \"df_step_1_cor.xlsx\")\n",
    "else:\n",
    "    if yes_or_no(\"영문명 수정이 필요합니다. 반복 점검하시겠습니까?\"):\n",
    "        repeat_eng()\n",
    "    else:\n",
    "        os.system(output_path + \"chk_eng.xlsx\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
